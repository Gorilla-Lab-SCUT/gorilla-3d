task: train  # train, test
seed: 123

data:
  data_root: ../../data
  filename_suffix: _inst_nostuff.pth

  ignore_label: -100
  with_elastic: False
  train_mini: False
  workers: 16 # data loader workers

  scale: 50   # voxel_size = 1 / scale, scale 50(2cm)
  batch_size: 4
  full_scale: [128, 512]
  max_npoint: 200000
  mode: 4 # 4=mean

  # train mode
  epochs: 384
  save_freq: 16  # also eval_freq

  # test mode
  split: val
  test_epoch: 384
  test_seed: 567
  test_workers: 8 # data loader workers

  TEST_NMS_THRESH: 0.3
  TEST_SCORE_THRESH: 0.09
  TEST_NPOINT_THRESH: 100

  eval: True
  save_semantic: False
  save_pt_offsets: False
  save_instance: False

model:
  input_channel: 3
  blocks: 5
  m: 32 # 16 or 32
  block_reps: 2
  classes: 20

  prepare_epochs: 128
  use_coords: True
  fix_module: []
  
  fg_thresh: 0.75
  bg_thresh: 0.25

  score_scale: 50 # the minimal voxel size is 2cm
  score_fullscale: 14
  score_mode: 4 # mean
  loss_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] # semantic_loss, offset_norm_loss, offset_dir_loss, score_loss

cluster:
  ### point grouping
  cluster_radius: 0.04
  cluster_radius_shift: 0.03
  cluster_meanActive: 50
  cluster_shift_meanActive: 300
  cluster_npoint_thre: 50

# optimizer
optimizer:
  lr: 0.002
  # name: Adam
  name: AdamW
  weight_decay: 0.0001
  # amsgrad: False

# lr_scheduler
lr_scheduler:
  name: PolyLR
  max_iters: 153600
  power: 0.9
  constant_ending: 0.0

